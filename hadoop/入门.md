# 0. 环境搭建
- [搭建环境](http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html)

- [集群信息查看](http://192.168.80.128:50070/)

- `jps`出来三个进程，NameNode、DataNode、SecondDataNode

# 1.HDFS常用命令
```shell
./start-dfs.sh
#启动NameNode、DataNode、SecondDataNode
./hdfs dfs -mkdir -p /user/huming
#创建文件夹
./hdfs dfs -put ../etc/hadoop /user/huming
#本地文件copy到分布式文件系统
./hdfs dfs -get /user/huming output
#从分布式文件系统copy文件到本地的文件系统,会自动创建文件夹
./hdfs dfs -cat output/*
sbin/stop-dfs.sh
```
